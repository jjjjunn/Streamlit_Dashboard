import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import time  
import folium
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_curve, auc, classification_report, mean_squared_error, mean_absolute_error
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
import plotly.graph_objs as go


# [íŒŒìŠ¤í…”í†¤ Hex Codes]
# íŒŒìŠ¤í…” ë¸”ë£¨: #ADD8E6
# íŒŒìŠ¤í…” ê·¸ë¦°: #77DD77
# íŒŒìŠ¤í…” í¼í”Œ: #B19CD9
# íŒŒìŠ¤í…” ì˜ë¡œìš°: #FFFACD
# íŒŒìŠ¤í…” í”¼ì¹˜: #FFDAB9
# íŒŒìŠ¤í…” ë¯¼íŠ¸: #BDFCC9
# íŒŒìŠ¤í…” ë¼ë²¤ë”: #E6E6FA
# íŒŒìŠ¤í…” ë…¸ë€ìƒ‰: #FFF44F
# íŒŒìŠ¤í…” ê·¸ë¦°: #B2FBA5

# ë©”ì¸ í˜ì´ì§€ ë„ˆë¹„ ë„“ê²Œ (ê°€ì¥ ì²˜ìŒì— ì„¤ì •í•´ì•¼ í•¨)
st.set_page_config(layout="wide") 

with st.spinner("ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”..."):
    time.sleep(1)  # ëŒ€ê¸° ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
st.success("Data Loaded!")

# í•œê¸€ ë° ë§ˆì´ë„ˆìŠ¤ ê¹¨ì§
plt.rcParams['font.family'] = "Malgun Gothic"
plt.rcParams['axes.unicode_minus'] = False

# í´ë¼ìš°ë“œ ë°°í¬ ì‹œ í•œê¸€, ë§ˆì´ë„ˆìŠ¤ ê¹¨ì§ ë°©ì§€


# CSV íŒŒì¼ ê²½ë¡œ ì„¤ì •
CSV_FILE_PATH = 'https://raw.githubusercontent.com/jjjjunn/YH_project/refs/heads/main/'


member_df = pd.read_csv(CSV_FILE_PATH + 'members_data.csv')
# member_df = pd.read_csv('https://raw.githubusercontent.com/jjjjunn/YH_project/refs/heads/main/members_data.csv')

# Streamlit emoji: https://streamlit-emoji-shortcodes-streamlit-app-gwckff.streamlit.app/

#ì˜¨/ì˜¤í”„ë¼ì¸ ë°ì´í„° ë¡œë“œ
@st.cache_data
def on_load_data():
    df_on = pd.read_csv(CSV_FILE_PATH + 'recycling_online.csv', encoding="UTF8").fillna(0)
    df_on.replace([np.inf, -np.inf], np.nan, inplace=True)
    df_on.fillna(0, inplace=True)
    return df_on

@st.cache_data
def off_load_data():
    df_off = pd.read_csv(CSV_FILE_PATH + 'recycling_off.csv', encoding="UTF8")
    df_off.replace([np.inf, -np.inf], np.nan, inplace=True)
    df_off.dropna(subset=["ë‚ ì§œ"], inplace=True)
    return df_off

df_on = on_load_data()
df_off = off_load_data()

print_df = member_df.rename(columns={
     "age": "ë‚˜ì´",
     "gender": "ì„±ë³„",
     "marriage": "í˜¼ì¸ì—¬ë¶€",
     "city": "ë„ì‹œ",
     "channel": "ê°€ì…ê²½ë¡œ",
     "before_ev": "ì°¸ì—¬_ì „",
     "part_ev": "ì°¸ì—¬ì´ë²¤íŠ¸",
     "after_ev": "ì°¸ì—¬_í›„"
})

# ë°ì´í„°ê°’ ë³€ê²½
print_df['ì„±ë³„'] = print_df['ì„±ë³„'].map({0:'ë‚¨ì', 1:'ì—¬ì'})
print_df['í˜¼ì¸ì—¬ë¶€'] = print_df['í˜¼ì¸ì—¬ë¶€'].map({0:'ë¯¸í˜¼', 1:'ê¸°í˜¼'})
print_df['ë„ì‹œ'] = print_df['ë„ì‹œ'].map({0:'ë¶€ì‚°', 1:'ëŒ€êµ¬', 2:'ì¸ì²œ', 3:'ëŒ€ì „', 4:'ìš¸ì‚°', 5:'ê´‘ì£¼', 6:'ì„œìš¸', 
    7:'ê²½ê¸°', 8:'ê°•ì›', 9:'ì¶©ë¶', 10:'ì¶©ë‚¨', 11:'ì „ë¶', 12:'ì „ë‚¨', 13:'ê²½ë¶', 14:'ê²½ë‚¨', 15:'ì„¸ì¢…', 16:'ì œì£¼'})
print_df['ê°€ì…ê²½ë¡œ'] = print_df['ê°€ì…ê²½ë¡œ'].map({0:"ì§ì ‘ ìœ ì…", 1:"í‚¤ì›Œë“œ ê²€ìƒ‰", 2:"ë¸”ë¡œê·¸", 3:"ì¹´í˜", 4:"ì´ë©”ì¼", 
        5:"ì¹´ì¹´ì˜¤í†¡", 6:"ë©”íƒ€", 7:"ì¸ìŠ¤íƒ€ê·¸ë¨", 8:"ìœ íŠœë¸Œ", 9:"ë°°ë„ˆ ê´‘ê³ ", 10:"íŠ¸ìœ„í„° X", 11:"ê¸°íƒ€ SNS"})
print_df['ì°¸ì—¬_ì „'] = print_df['ì°¸ì—¬_ì „'].map({0:'ê°€ì…', 1:'ë¯¸ê°€ì…'})
print_df['ì°¸ì—¬ì´ë²¤íŠ¸'] = print_df['ì°¸ì—¬ì´ë²¤íŠ¸'].map({0:"ì›Œí¬ìˆ ê°œìµœ", 1:"ì¬í™œìš© í’ˆëª© ìˆ˜ì§‘ ì´ë²¤íŠ¸", 2:"ì¬í™œìš© ì•„íŠ¸ ì „ì‹œ",
          3:"ê²Œì„ ë° í€´ì¦ˆ", 4:"ì»¤ë®¤ë‹ˆí‹° ì²­ì†Œ í™œë™", 5:"ì—…ì‚¬ì´í´ë§ ë§ˆì¼“", 6:"í™ë³´ ë¶€ìŠ¤ ìš´ì˜"})
print_df['ì°¸ì—¬_í›„'] = print_df['ì°¸ì—¬_í›„'].map({0:'ê°€ì…', 1:'ë¯¸ê°€ì…'})

# íŠ¹ì„± ê³µí•™ í•¨ìˆ˜ ì¶”ê°€
def create_features(data):
    """íŠ¹ì„± ê³µí•™ì„ í†µí•´ ìƒˆë¡œìš´ ë³€ìˆ˜ ìƒì„±"""
    data_copy = data.copy()
    
    # ì—°ë ¹ëŒ€ ê·¸ë£¹ ìƒì„±
    data_copy['age_group'] = pd.cut(data_copy['age'], 
                                   bins=[0, 30, 40, 50, 100], 
                                   labels=['20ëŒ€', '30ëŒ€', '40ëŒ€', '50ëŒ€ì´ìƒ'])
    
    # ì„±ë³„-í˜¼ì¸ìƒíƒœ ì¡°í•© ë³€ìˆ˜
    data_copy['gender_marriage'] = data_copy['gender'].astype(str) + '_' + data_copy['marriage'].astype(str)
    
    # ë„ì‹œ ê·œëª¨ë³„ ê·¸ë£¹ (ëŒ€ë„ì‹œ, ì¤‘ì†Œë„ì‹œ ë“±)
    metro_cities = [6, 7]  # ì„œìš¸, ê²½ê¸°
    major_cities = [0, 1, 2, 3, 4, 5]  # ë¶€ì‚°, ëŒ€êµ¬, ì¸ì²œ, ëŒ€ì „, ìš¸ì‚°, ê´‘ì£¼
    data_copy['city_type'] = data_copy['city'].apply(
        lambda x: 'metro' if x in metro_cities else 'major' if x in major_cities else 'other'
    )
    
    return data_copy

data = create_features(member_df[['age', 'city', 'gender', 'marriage', 'after_ev']])

tab1, tab2, tab3, tab4, tab5 = st.tabs(['ì„œë¹„ìŠ¤ê°€ì… ì˜ˆì¸¡', 'ì¶”ì²œ ìº í˜ì¸', 'ì¶”ì²œ ì±„ë„', 'ì „í™˜ìœ¨ ì˜ˆì¸¡', 'ë°©ë¬¸ììˆ˜ ì˜ˆì¸¡'])

with tab1: # ì„œë¹„ìŠ¤ ê°€ì… ì˜ˆì¸¡ ëª¨ë¸
    with st.expander('íšŒì› ë°ì´í„°'):
        st.dataframe(print_df, use_container_width=True)
    col1, col2, col3 = st.columns([4, 3, 3])
    with col1:
        st.write("ì„œë¹„ìŠ¤ê°€ì… ì˜ˆì¸¡ ëª¨ë¸ì…ë‹ˆë‹¤. ì•„ë˜ì˜ ì¡°ê±´ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
        ages_1 = st.slider(
            "ì—°ë ¹ëŒ€ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.",
            25, 65, (35, 45)
        )
        st.write(f"**ì„ íƒ ì—°ë ¹ëŒ€: :red[{ages_1}]ì„¸**")

    with col2:
        gender_1 = st.radio(
            "ì„±ë³„ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.",
            ["ë‚¨ì", "ì—¬ì"],
            index=0
        )
    
    with col3:
        marriage_1 = st.radio(
            "í˜¼ì¸ì—¬ë¶€ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.",
            ["ë¯¸í˜¼", "ê¸°í˜¼"],
            index=0
        )
    
    # ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ í•¨ìˆ˜
    @st.cache_data
    def train_model(data):
        numeric_features = ['age']
        categorical_features = ['gender', 'marriage', 'city', 'age_group', 'gender_marriage', 'city_type']

        # ColumnTransformer ì„¤ì •
        preprocessor = ColumnTransformer(
            transformers=[
                ('num', StandardScaler(), numeric_features), # ìˆ˜ì¹˜í˜• - í‘œì¤€í™” 
                ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features) # ë²”ì£¼í˜• - ì›í•«ì¸ì½”ë”©
            ]
        )

        # ì—¬ëŸ¬ ëª¨ë¸ ì •ì˜
        rf_model = RandomForestClassifier(
            n_estimators=200,
            max_depth=15,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=42,
            n_jobs=-1,
            class_weight='balanced'
        )
        
        gb_model = GradientBoostingClassifier(
            n_estimators=150,
            learning_rate=0.1,
            max_depth=6,
            random_state=42
        )
        
        lr_model = LogisticRegression(
            random_state=42,
            class_weight='balanced',
            max_iter=1000
        )

        # ì•™ìƒë¸” ëª¨ë¸ ìƒì„±
        ensemble_model = VotingClassifier(
            estimators=[
                ('rf', Pipeline([('preprocessor', preprocessor), ('classifier', rf_model)])),
                ('gb', Pipeline([('preprocessor', preprocessor), ('classifier', gb_model)])),
                ('lr', Pipeline([('preprocessor', preprocessor), ('classifier', lr_model)]))
            ],
            voting='soft'
        )

        # ë°ì´í„° ë¶„í•  (ê³„ì¸µí™” ìƒ˜í”Œë§)
        X = data.drop(columns=['after_ev'])
        y = data['after_ev']
        
        # ê³„ì¸µí™” ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )

        # êµì°¨ê²€ì¦ì„ í†µí•œ ëª¨ë¸ í‰ê°€
        cv_scores = cross_val_score(ensemble_model, X_train, y_train, 
                                   cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), 
                                   scoring='f1')
        
        # ëª¨ë¸ í•™ìŠµ
        ensemble_model.fit(X_train, y_train)

        return ensemble_model, X_test, y_test, cv_scores

    # ì„±ëŠ¥ í‰ê°€ ë° ì§€í‘œ ì¶œë ¥ í•¨ìˆ˜
    def evaluate_model(model, X_test, y_test, cv_scores):
        y_pred = model.predict(X_test)
        y_pred_proba = model.predict_proba(X_test)[:, 1]

        # ì„±ëŠ¥ í‰ê°€
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)

        # êµì°¨ê²€ì¦ ê²°ê³¼ í¬í•¨
        st.write(f"**êµì°¨ê²€ì¦ F1 ì ìˆ˜: {cv_scores.mean():.3f} (Â±{cv_scores.std() * 2:.3f})**")
        st.write(f"**í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ - ì •í™•ë„: {accuracy * 100:.1f}%, ì •ë°€ë„: {precision * 100:.1f}%, ì¬í˜„ìœ¨: {recall * 100:.1f}%**")
        st.write(f"**F1-Score: {f1 * 100:.1f}%**")

        # ìƒì„¸ ë¶„ë¥˜ ë¦¬í¬íŠ¸
        with st.expander("ìƒì„¸ ë¶„ë¥˜ ë¦¬í¬íŠ¸"):
            st.text(classification_report(y_test, y_pred, target_names=['ê°€ì…', 'ë¯¸ê°€ì…']))

        return y_pred, y_pred_proba

    # ì‹œê°í™” í•¨ìˆ˜ (í˜¼ë™ í–‰ë ¬ ë° ROC ê³¡ì„ )
    def plot_metrics(y_test, y_pred, y_pred_proba):
        cm = confusion_matrix(y_test, y_pred)
        
        y_scores = y_pred_proba  # ê¸ì • í´ë˜ìŠ¤ í™•ë¥ 
        fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
        roc_auc = auc(fpr, tpr)

        # ì²« ë²ˆì§¸ ì—´ì— í˜¼ë™ í–‰ë ¬ ì‹œê°í™”
        col1, col2 = st.columns(2)

        with col1:
            # í˜¼ë™ í–‰ë ¬ ì‹œê°í™”
            cm_df = pd.DataFrame(cm, index=['ë¯¸ê°€ì…', 'ê°€ì…'], columns=['ë¯¸ê°€ì…', 'ê°€ì…'])
            fig = px.imshow(cm_df, text_auto=True, color_continuous_scale='GnBu', 
                            title='í˜¼ë™ í–‰ë ¬ (Confusion Matrix)')
            fig.update_xaxes(title='ì˜ˆì¸¡ ë ˆì´ë¸”')
            fig.update_yaxes(title='ì‹¤ì œ ë ˆì´ë¸”')
            fig.update_layout(width=600, height=600)
            st.plotly_chart(fig)
            
            # í˜¼ë™ í–‰ë ¬ í•´ì„ ì¶”ê°€
            tn, fp, fn, tp = cm.ravel()
            st.write("**í˜¼ë™ í–‰ë ¬ í•´ì„:**")
            st.write(f"- ì°¸ ìŒì„± (TN): {tn}ê°œ - ë¯¸ê°€ì…ì„ ë¯¸ê°€ì…ìœ¼ë¡œ ì •í™•íˆ ì˜ˆì¸¡")
            st.write(f"- ê±°ì§“ ì–‘ì„± (FP): {fp}ê°œ - ë¯¸ê°€ì…ì„ ê°€ì…ìœ¼ë¡œ ì˜ëª» ì˜ˆì¸¡")  
            st.write(f"- ê±°ì§“ ìŒì„± (FN): {fn}ê°œ - ê°€ì…ì„ ë¯¸ê°€ì…ìœ¼ë¡œ ì˜ëª» ì˜ˆì¸¡")
            st.write(f"- ì°¸ ì–‘ì„± (TP): {tp}ê°œ - ê°€ì…ì„ ê°€ì…ìœ¼ë¡œ ì •í™•íˆ ì˜ˆì¸¡")
    
        with col2:
            # ROC ê³¡ì„  ì‹œê°í™”
            fig_roc = go.Figure()
            
            # ROC ê³¡ì„  ì¶”ê°€
            fig_roc.add_trace(go.Scatter(
                x=fpr, y=tpr, 
                mode='lines', 
                name=f'ROC curve (AUC = {roc_auc:.3f})', 
                line=dict(width=2, color='blue')
            ))
            
            # ëœë¤ ë¶„ë¥˜ê¸° (ëŒ€ê°ì„ ) ì¶”ê°€
            fig_roc.add_trace(go.Scatter(
                x=[0, 1], y=[0, 1], 
                mode='lines', 
                name='Random Classifier (AUC = 0.5)', 
                line=dict(width=2, dash='dash', color='red')
            ))
            
            # ë ˆì´ì•„ì›ƒ ì„¤ì •
            fig_roc.update_layout(
                title='ROC ê³¡ì„  (Receiver Operating Characteristic)',
                xaxis_title='False Positive Rate (ê±°ì§“ ì–‘ì„±ë¥ )',
                yaxis_title='True Positive Rate (ì°¸ ì–‘ì„±ë¥ )',
                showlegend=True,
                width=600,
                height=600,
                xaxis=dict(range=[0, 1]),
                yaxis=dict(range=[0, 1])
            )
            
            # Streamlitì—ì„œ ROC ê³¡ì„  ê·¸ë˜í”„ í‘œì‹œ
            st.plotly_chart(fig_roc)
            
            # ROC AUC í•´ì„ ì¶”ê°€
            st.write("**ROC AUC í•´ì„:**")
            if roc_auc >= 0.9:
                st.write(f"ğŸŸ¢ AUC = {roc_auc:.3f} - ë§¤ìš° ìš°ìˆ˜í•œ ì„±ëŠ¥")
            elif roc_auc >= 0.8:
                st.write(f"ğŸ”µ AUC = {roc_auc:.3f} - ìš°ìˆ˜í•œ ì„±ëŠ¥")
            elif roc_auc >= 0.7:
                st.write(f"ğŸŸ¡ AUC = {roc_auc:.3f} - ì–‘í˜¸í•œ ì„±ëŠ¥")
            elif roc_auc >= 0.6:
                st.write(f"ğŸŸ  AUC = {roc_auc:.3f} - ë³´í†µ ì„±ëŠ¥")
            else:
                st.write(f"ğŸ”´ AUC = {roc_auc:.3f} - ê°œì„  í•„ìš”")

    # ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥ í•¨ìˆ˜
    def pre_result(model, new_data):
        prediction = model.predict(new_data)
        prediction_proba = model.predict_proba(new_data)

        result_text = 'ê°€ì…' if prediction[0] == 0 else 'ë¯¸ê°€ì…'
        confidence = prediction_proba[0][prediction[0]] * 100
        
        st.write(f"**ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼: :rainbow[{result_text}] (ì‹ ë¢°ë„: {confidence:.1f}%)**")

    # ë²„íŠ¼ í´ë¦­ì— ë”°ë¥¸ ë™ì‘
    if st.button("ì˜ˆì¸¡í•˜ê¸°"):
        # ì…ë ¥ëœ ê°’ì„ ìƒˆë¡œìš´ ë°ì´í„° í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        new_data = pd.DataFrame({
            'age': [(ages_1[0] + ages_1[1]) / 2],
            'gender': [1 if gender_1 == 'ì—¬ì' else 0],
            'marriage': [1 if marriage_1 == 'ê¸°í˜¼' else 0],
            'city': [6]  # ê¸°ë³¸ê°’ìœ¼ë¡œ ì„œìš¸ ì„¤ì •
        })

        # íŠ¹ì„± ê³µí•™ ì ìš©
        new_data = create_features(new_data)

        # ê¸°ì¡´ ë°ì´í„°ë¡œ ëª¨ë¸ í•™ìŠµ
        ensemble_model, X_test, y_test, cv_scores = train_model(data)

        # ì˜ˆì¸¡ ìˆ˜í–‰
        pre_result(ensemble_model, new_data)

        # ì„±ëŠ¥ í‰ê°€ ë° ì§€í‘œ ì¶œë ¥
        y_pred, y_pred_proba = evaluate_model(ensemble_model, X_test, y_test, cv_scores)

        # ì‹œê°í™”
        plot_metrics(y_test, y_pred, y_pred_proba)


# ìº í˜ì¸ ì¶”ì²œ ëª¨ë¸
data_2 = create_features(member_df[['age', 'city', 'gender', 'marriage', 'before_ev', 'part_ev', 'after_ev']])

# ì°¸ì—¬ ì´ë²¤íŠ¸ ë§¤í•‘
event_mapping = {
    0: "ì›Œí¬ìˆ ê°œìµœ",
    1: "ì¬í™œìš© í’ˆëª© ìˆ˜ì§‘ ì´ë²¤íŠ¸",
    2: "ì¬í™œìš© ì•„íŠ¸ ì „ì‹œ",
    3: "ê²Œì„ ë° í€´ì¦ˆ",
    4: "ì»¤ë®¤ë‹ˆí‹° ì²­ì†Œ í™œë™",
    5: "ì—…ì‚¬ì´í´ë§ ë§ˆì¼“",
    6: "í™ë³´ ë¶€ìŠ¤ ìš´ì˜"
}

city_mapping = {
    0: 'ë¶€ì‚°',
    1: 'ëŒ€êµ¬', 
    2: 'ì¸ì²œ', 
    3: 'ëŒ€ì „', 
    4: 'ìš¸ì‚°', 
    5: 'ê´‘ì£¼', 
    6: 'ì„œìš¸', 
    7: 'ê²½ê¸°', 
    8: 'ê°•ì›', 
    9: 'ì¶©ë¶', 
    10: 'ì¶©ë‚¨', 
    11: 'ì „ë¶', 
    12: 'ì „ë‚¨', 
    13: 'ê²½ë¶', 
    14: 'ê²½ë‚¨', 
    15: 'ì„¸ì¢…', 
    16: 'ì œì£¼'
}

with tab2: # ìº í˜ì¸ ì¶”ì²œ ëª¨ë¸
    with st.expander('íšŒì› ë°ì´í„°'):
        st.dataframe(print_df, use_container_width=True)
    col1, col2, col3 = st.columns([4, 3, 3])
    with col1:
        st.write("ìº í˜ì¸ ì¶”ì²œ ëª¨ë¸ì…ë‹ˆë‹¤. ì•„ë˜ì˜ ì¡°ê±´ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
        ages_2 = st.slider(
            "ì—°ë ¹ëŒ€ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.",
            25, 65, (35, 45),
            key='slider_2'
        )
        st.write(f"**ì„ íƒ ì—°ë ¹ëŒ€: :red[{ages_2}]ì„¸**")
        
    with col2:
        gender_2 = st.radio(
            "ì„±ë³„ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.",
            ["ë‚¨ì", "ì—¬ì"],
            index=0,
            key='radio2_1'
        )
    
    with col3:
        marriage_2 = st.radio(
            "í˜¼ì¸ì—¬ë¶€ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.",
            ["ë¯¸í˜¼", "ê¸°í˜¼"],
            index=0,
            key='radio2_2'
        )

    # ì¶”ì²œ ëª¨ë¸ í•¨ìˆ˜
    @st.cache_data
    def calculate_enrollment_increase_rate(data):
        #ìº í˜ì¸ ë³„ ê°€ì… ì¦ê°€ìœ¨ ê³„ì‚°
        increase_rates = {}
        campaign_stats = {}
        
        # ì¡°ê±´ë³„ ìº í˜ì¸ ê·¸ë£¹í™” ë° ê³„ì‚°
        campaign_groups = data.groupby('part_ev')
        
        for campaign, group in campaign_groups:
            # ìº í˜ì¸ì „ê³¼ í›„ì˜ ê°€ì…ì ìˆ˜ ê³„ì‚°
            pre_signups = (group['before_ev'] == 0).sum()  # ìº í˜ì¸ ì „ ê°€ì…ì ìˆ˜ (0ì˜ ìˆ˜)
            post_signups = (group['after_ev'] == 0).sum()  # ìº í˜ì¸ í›„ ê°€ì…ì ìˆ˜ (0ì˜ ìˆ˜)
            total_participants = len(group)
            
            # ì „í™˜ìœ¨ ê³„ì‚°
            if total_participants > 0:
                conversion_rate = post_signups / total_participants
                # ë² ì´ì¦ˆ ì¶”ì •ìœ¼ë¡œ ì‹ ë¢°êµ¬ê°„ ê³„ì‚°
                alpha = post_signups + 1
                beta = total_participants - post_signups + 1
                mean_rate = alpha / (alpha + beta)
                
                increase_rates[campaign] = mean_rate
                campaign_stats[campaign] = {
                    'conversion_rate': conversion_rate,
                    'participants': total_participants,
                    'signups': post_signups
                }
            else:
                increase_rates[campaign] = 0
                campaign_stats[campaign] = {
                    'conversion_rate': 0,
                    'participants': 0,
                    'signups': 0
                }

        return increase_rates, campaign_stats

    def recommend_campaign(data, age_range, gender, marriage):
    # ì¡°ê±´ì— ë”°ë¼ ë°ì´í„° í•„í„°ë§
        filtered_data = data[
            (data['age'].between(age_range[0], age_range[1])) &
            (data['gender'] == (1 if gender == 'ì—¬ì' else 0)) &
            (data['marriage'] == (1 if marriage == 'ê¸°í˜¼' else 0))
        ]

        if filtered_data.empty:
            return "í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # ê°€ì… ì¦ê°€ìœ¨ ê³„ì‚°
        increase_rates, campaign_stats = calculate_enrollment_increase_rate(filtered_data)

        # ê°€ì¥ ë†’ì€ ê°€ì… ì¦ê°€ìœ¨ì„ ê°€ì§„ ìº í˜ì¸ ì¶”ì²œ
        best_campaign = max(increase_rates, key=increase_rates.get)
        
        return best_campaign, increase_rates, campaign_stats

    # ì‚¬ìš©ì ì •ë³´ ì…ë ¥ì„ í†µí•œ ì¶”ì²œ ì´ë²¤íŠ¸ í‰ê°€
    if st.button("ìº í˜ì¸ ì¶”ì²œ ë°›ê¸°"):
        best_campaign, increase_rates, campaign_stats = recommend_campaign(data_2, ages_2, gender_2, marriage_2)
            
        if isinstance(best_campaign, str):
            st.write(best_campaign)
        else:
            st.write(f"**ì¶”ì²œ ìº í˜ì¸: :violet[{event_mapping[best_campaign]}] ğŸ‘ˆ ì´ ìº í˜ì¸ì´ ê°€ì¥ ê°€ì…ì„ ìœ ë„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!**")

            # ìƒì„¸ í†µê³„ ì •ë³´ ì¶œë ¥
            best_stats = campaign_stats[best_campaign]
            st.write(f"**ì¶”ì²œ ê·¼ê±°: ì°¸ì—¬ì {best_stats['participants']}ëª… ì¤‘ {best_stats['signups']}ëª… ê°€ì… (ì „í™˜ìœ¨: {best_stats['conversion_rate']:.1%})**")
            
            # ê°€ì… ì¦ê°€ìœ¨ ê²°ê³¼ ì¶œë ¥
            with st.expander("**ê° ìº í˜ì¸ë³„ ê°€ì… ì¦ê°€ìœ¨ ë³´ê¸°**"):
                for campaign, rate in increase_rates.items():
                    stats = campaign_stats[campaign]
                    st.write(f"**{event_mapping[campaign]}**: ì „í™˜ìœ¨ {rate:.1%} (ì°¸ì—¬ì: {stats['participants']}ëª…, ê°€ì…: {stats['signups']}ëª…)")
            
            # ê°€ì… ì¦ê°€ìœ¨ ê²°ê³¼ ì¶œë ¥ ë° ê°€ë¡œ ë§‰ëŒ€ê·¸ë˜í”„ í‘œì‹œ
            campaigns, rates = zip(*increase_rates.items())
            campaigns = [event_mapping[campaign] for campaign in campaigns]  # ë§¤í•‘ëœ ìº í˜ì¸ ì´ë¦„
            
            # íŒŒìŠ¤í…” í†¤ ìƒ‰ìƒ ë¦¬ìŠ¤íŠ¸ ìƒì„±
            pastel_colors = ['#FF9999', '#66B3FF', '#99FF99', '#FFCC99', '#77DD77', '#B19CD9', '#FFDAB9']

            # ê°€ë¡œ ë§‰ëŒ€ê·¸ë˜í”„ ì‹œê°í™”
            fig_bar = go.Figure()

            # ê°€ë¡œ ë§‰ëŒ€ ì¶”ê°€
            fig_bar.add_trace(go.Bar(
                y=campaigns,  # ìº í˜ì¸ ì´ë¦„
                x=rates,      # ê°€ì… ì¦ê°€ìœ¨
                orientation='h',  # ê°€ë¡œ ë§‰ëŒ€ê·¸ë˜í”„
                marker=dict(color=pastel_colors),  # ìƒ‰ìƒ ì„¤ì •
            ))

            # 0 ì„  ì¶”ê°€
            fig_bar.add_shape(
                type='line',
                x0=0,
                y0=-0.5,
                x1=0,
                y1=len(campaigns) - 0.5,
                line=dict(color='gray', width=0.8),
            )

            # ë ˆì´ì•„ì›ƒ ì„¤ì •
            fig_bar.update_layout(
                title='ìº í˜ì¸ë³„ ê°€ì… ì¦ê°€ìœ¨',
                xaxis_title='ê°€ì… ì¦ê°€ìœ¨',
                height=600
            )

            # Xì¶• ì„¤ì •
            fig_bar.update_xaxes(
                range=[min(min(rates), 0), max(max(rates), 0)],  # Xì¶• ë²”ìœ„ ì„¤ì •
                showgrid=True
            )

            # Yì¶• ì„¤ì •
            fig_bar.update_yaxes(
                title='ìº í˜ì¸',
                showgrid=False
            )

            # Streamlitì—ì„œ ê°€ë¡œ ë§‰ëŒ€ê·¸ë˜í”„ í‘œì‹œ
            st.plotly_chart(fig_bar)

# ë§ˆì¼€íŒ… ì±„ë„ ì¶”ì²œ 
data_3 = member_df[['age', 'gender', 'marriage', 'channel', 'before_ev']]

# ê°€ì… ì‹œ ìœ ì…ê²½ë¡œ ë§¤í•‘
register_channel = {
    0:"ì§ì ‘ ìœ ì…",
    1:"í‚¤ì›Œë“œ ê²€ìƒ‰",
    2:"ë¸”ë¡œê·¸",
    3:"ì¹´í˜",
    4:"ì´ë©”ì¼",
    5:"ì¹´ì¹´ì˜¤í†¡",
    6:"ë©”íƒ€",
    7:"ì¸ìŠ¤íƒ€ê·¸ë¨",
    8:"ìœ íŠœë¸Œ", 
    9:"ë°°ë„ˆ ê´‘ê³ ", 
    10:"íŠ¸ìœ„í„° X", 
    11:"ê¸°íƒ€ SNS"
}

with tab3: # ë§ˆì¼€íŒ… ì±„ë„ ì¶”ì²œ ëª¨ë¸
    with st.expander('íšŒì› ë°ì´í„°'):
        st.dataframe(print_df, use_container_width=True)
    col1, col2, col3 = st.columns([6, 2, 2])
    with col1:
        st.write("ë§ˆì¼€íŒ… ì±„ë„ ì¶”ì²œ ëª¨ë¸ì…ë‹ˆë‹¤. ì•„ë˜ì˜ ì¡°ê±´ì„ ì„ íƒí•´ ì£¼ì„¸ìš”")
        ages_3 = st.slider(
            "ì—°ë ¹ëŒ€ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.",
            25, 65, (35, 45),
            key='slider_3'
        )
        st.write(f"**ì„ íƒ ì—°ë ¹ëŒ€: :red[{ages_3}]ì„¸**")
    
    with col2:
        gender_3 = st.radio(
            "ì„±ë³„ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.",
            ["ë‚¨ì", "ì—¬ì"],
            index=0,
            key='radio3_1'
        )
    
    with col3:
        marriage_3 = st.radio(
            "í˜¼ì¸ì—¬ë¶€ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.",
            ["ë¯¸í˜¼", "ê¸°í˜¼"],
            index=0,
            key='radio3_2'
        )

    # ì¶”ì²œ ëª¨ë¸ í•¨ìˆ˜
    @st.cache_data
    def calculate_channel_conversion_rate(data):
        # ë§ˆì¼€íŒ… ì±„ë„ë³„ ê°€ì…ë¥  ê³„ì‚°
        channel_stats = data.groupby('channel').agg(
        total_members=('before_ev', 'count'),   # ì „ì²´ ìœ ì…ì ìˆ˜
        total_signups=('before_ev', lambda x: (x == 0).sum())  # ê°€ì…ì ìˆ˜ (before_evê°€ 0ì¸ ê²½ìš°)
        )
        
        # ê°€ì…ë¥  ê³„ì‚°: ê°€ì…ìì˜ ìˆ˜ / ì „ì²´ ìœ ì…ìì˜ ìˆ˜
        channel_stats['conversion_rate'] = channel_stats['total_signups'] / channel_stats['total_members']
        channel_stats.reset_index(inplace=True)
        return channel_stats[['channel', 'conversion_rate']]

    def recommend_channel(data, age_range, gender, marriage):
        #ì¡°ê±´ì— ë§ëŠ” ê°€ì¥ ì¶”ì²œ ë§ˆì¼€íŒ… ì±„ë„ 3ê°œë¥¼ ë°˜í™˜
        filtered_data = data[
            (data['age'].between(age_range[0], age_range[1])) &
            (data['gender'] == (1 if gender == 'ì—¬ì' else 0)) &
            (data['marriage'] == (1 if marriage == 'ê¸°í˜¼' else 0))
        ]

        channel_rates = calculate_channel_conversion_rate(filtered_data)
        
        # "ì§ì ‘ ìœ ì…" ì±„ë„ ì œì™¸
        channel_rates = channel_rates[channel_rates['channel'] != 0]
        
        top_channels = channel_rates.nlargest(3, 'conversion_rate')
        
        return top_channels

    def display_channel_rates(channel_rates):
        #ë§ˆì¼€íŒ… ì±„ë„ ê°€ì…ë¥  ìˆ˜ì¹˜ í‘œì‹œ
        with st.expander("**ê° ë§ˆì¼€íŒ… ì±„ë„ë³„ ê°€ì…ë¥  ë³´ê¸°**"):
            for _, row in channel_rates.iterrows():
                channel_name = register_channel[row['channel']]
                st.write(f"{channel_name}: {row['conversion_rate']:.2%}")

    def plot_channel_rates(channel_rates):
        #ë§ˆì¼€íŒ… ì±„ë„ ê°€ì…ë¥  ì‹œê°í™” (ë§‰ëŒ€ ê·¸ë˜í”„)
        fig_bar = go.Figure()

        # íŒŒìŠ¤í…” í†¤ ìƒ‰ìƒ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        pastel_colors = ['#FFDAB9', '#BDFCC9', '#E6E6FA']

        fig_bar.add_trace(go.Bar(
            y=channel_rates['channel'].apply(lambda x: register_channel[x]),
            x = channel_rates['conversion_rate'],
            orientation='h',
            marker=dict(color=pastel_colors),
        ))

        # ì„ ì¶”ê°€
        fig_bar.add_shape(
            type='line',
            x0=0,
            y0=-0.5,
            x1=0,
            y1=len(channel_rates) - 0.5,  # Yì¶• ê°œìˆ˜
            line=dict(color='gray', width=0.8),
        )

        # ë ˆì´ì•„ì›ƒ ì„¤ì •
        fig_bar.update_layout(
            title='ë§ˆì¼€íŒ… ì±„ë„ë³„ ê°€ì…ë¥ ',
            xaxis_title='ê°€ì…ë¥ ',
            height=600
        )

        # Xì¶• ì„¤ì •
        fig_bar.update_xaxes(
            range=[min(min(channel_rates['conversion_rate']), 0), max(max(channel_rates['conversion_rate']), 0)],
            showgrid=True
        )

        # yì¶• ì„¤ì •
        fig_bar.update_yaxes(
            title='ë§ˆì¼€íŒ… ì±„ë„',
            showgrid=False)
        
        # í‘œì‹œ
        st.plotly_chart(fig_bar)

    # ì‚¬ìš©ì ì •ë³´ ì…ë ¥ì„ í†µí•œ ì¶”ì²œ ì´ë²¤íŠ¸ í‰ê°€
    if st.button("íš¨ê³¼ì ì¸ ë§ˆì¼€íŒ… ì±„ë„ ì¶”ì²œë°›ê¸°"):
        # ì¶”ì²œ ëª¨ë¸ í›ˆë ¨
        top_channels = recommend_channel(data_3, ages_3, gender_3, marriage_3)

        if not top_channels.empty:
            st.write(f"**ì¶”ì²œ ë§ˆì¼€íŒ… ì±„ë„:** :violet[{', '.join(top_channels['channel'].apply(lambda x: register_channel[x]))}] ğŸ‘ˆ ì´ ì±„ë„ë“¤ì´ ê°€ì¥ íš¨ê³¼ì ì…ë‹ˆë‹¤!")
            display_channel_rates(top_channels)
            plot_channel_rates(top_channels)
        else:
            st.write("í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ë§ˆì¼€íŒ… ì±„ë„ì´ ì—†ìŠµë‹ˆë‹¤.")

with tab4:  #ì „í™˜ìœ¨ ì˜ˆì¸¡
    # ë°ì´í„° ë¡œë“œ
    with st.expander('ì˜¨ë¼ì¸ ë°ì´í„°'):
        st.dataframe(df_on, use_container_width=True)
    select_all_device = st.checkbox("ë””ë°”ì´ìŠ¤ ì „ì²´ ì„ íƒ")
    device_options = df_on["ë””ë°”ì´ìŠ¤"].unique().tolist()
    select_all_path = st.checkbox("ìœ ì…ê²½ë¡œ ì „ì²´ ì„ íƒ")
    path_options = df_on["ìœ ì…ê²½ë¡œ"].unique().tolist()

    if select_all_device:
        select_device = st.multiselect("ë””ë°”ì´ìŠ¤", device_options, default = device_options)        
    else:
        select_device = st.multiselect("ë””ë°”ì´ìŠ¤", device_options)

    if select_all_path:
        select_path = st.multiselect("ìœ ì…ê²½ë¡œ", path_options, default = path_options)
    else:
        select_path = st.multiselect("ìœ ì…ê²½ë¡œ", path_options)
    time_input = st.slider("ì²´ë¥˜ ì‹œê°„(ë¶„)", min_value = 0, max_value = 100, value = 0, step = 5)
        
    #ì˜¨ë¼ì¸ ë°ì´í„° ë³µì‚¬
    df_ml_on = df_on.copy()

    # ê²°ì¸¡ê°’ ì²˜ë¦¬ (í•™ìŠµ ì „ì— ë¯¸ë¦¬ ì²˜ë¦¬)
    df_ml_on["ì „í™˜ìœ¨(ê°€ì…)"] = df_ml_on["ì „í™˜ìœ¨(ê°€ì…)"].fillna(df_ml_on["ì „í™˜ìœ¨(ê°€ì…)"].median())
    df_ml_on["ì²´ë¥˜ì‹œê°„(min)"] = df_ml_on["ì²´ë¥˜ì‹œê°„(min)"].fillna(df_ml_on["ì²´ë¥˜ì‹œê°„(min)"].median())

    # ì›-í•« ì¸ì½”ë”©
    df_ml_on = pd.get_dummies(df_ml_on, columns = ["ë””ë°”ì´ìŠ¤", "ìœ ì…ê²½ë¡œ"], drop_first=False)         

    #ì²´ë¥˜ì‹œê°„ ë° ì›-í•« ì¸ì½”ë”©ëœ ë””ë°”ì´ìŠ¤, ìœ ì…ê²½ë¡œ ë° íƒ€ê²Ÿ ë³€ìˆ˜ ì„¤ì •
    features = ["ì²´ë¥˜ì‹œê°„(min)"] + [col for col in df_ml_on.columns if "ë””ë°”ì´ìŠ¤_" in col or "ìœ ì…ê²½ë¡œ_" in col]
    target = "ì „í™˜ìœ¨(ê°€ì…)"

    if st.button("ì˜¨ë¼ì¸ ì „í™˜ìœ¨ ì˜ˆì¸¡"):
        # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
        if df_ml_on[target].isnull().sum() > 0:
            st.warning("ë°ì´í„°ì— ê²°ì¸¡ê°’ì´ ìˆìŠµë‹ˆë‹¤. ì „ì²˜ë¦¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            
        #ì…ë ¥(X), ì¶œë ¥(y) ë°ì´í„° ì •ì˜
        X = df_ml_on[features]
        y = df_ml_on[target]

        # ë°ì´í„° í‘œì¤€í™”
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        X_scaled = pd.DataFrame(X_scaled, columns=features)
        
        #í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• (í•™ìŠµ ë°ì´í„° : 80%, í…ŒìŠ¤íŠ¸ ë°ì´í„° : 20%)
        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2, random_state = 42, shuffle=True)


        #ëœë¤ í¬ë ˆìŠ¤íŠ¸ íšŒê·€ ëª¨ë¸ ìƒì„±
        on_model = RandomForestRegressor(
            n_estimators=200,           # íŠ¸ë¦¬ ê°œìˆ˜ ì¦ê°€
            max_depth=15,               # ê¹Šì´ ì¦ê°€
            min_samples_split=5,        # ë¶„í•  ìµœì†Œ ìƒ˜í”Œ ìˆ˜
            min_samples_leaf=2,         # ë¦¬í”„ ë…¸ë“œ ìµœì†Œ ìƒ˜í”Œ ìˆ˜
            max_features='sqrt',        # í”¼ì²˜ ì„ íƒ ë°©ë²•
            random_state=42,
            n_jobs=-1,
            oob_score=True              # Out-of-bag ì ìˆ˜ ê³„ì‚°
        )

        #  ëª¨ë¸ í•™ìŠµ
        on_model.fit(X_train, y_train)

        #í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡
        y_pred = on_model.predict(X_test)

        # ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        # ì„±ëŠ¥ ì§€í‘œ ì¶œë ¥
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("RMSE", f"{rmse:.3f}")
        with col2:
            st.metric("MAE", f"{mae:.3f}")
        with col3:
            st.metric("RÂ² Score", f"{r2:.3f}")
        with col4:
            st.metric("OOB Score", f"{on_model.oob_score_:.3f}")

        #âœ…ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”(ì‹¤ì œ ì „í™˜ìœ¨ VS ì˜ˆì¸¡ ì „í™˜ìœ¨ ë¹„êµ)
        fig_ml_on = go.Figure()

        # ì‹¤ì œ ê°’ê³¼ ì˜ˆì¸¡ ê°’ ë¹„êµë¥¼ ìœ„í•œ ì‚°ì ë„ ì¶”ê°€
        fig_ml_on.add_trace(go.Scatter(
            x=y_test,         # ì‹¤ì œ ê°’
            y=y_pred,         # ì˜ˆì¸¡ ê°’
            mode='markers+lines',  # ë§ˆì»¤ì™€ ì„ ì„ ë™ì‹œì— í‘œì‹œ
            marker=dict(symbol='circle', size=8, color='blue', line=dict(width=2)),
            line=dict(shape='linear'),
            name='ì˜ˆì¸¡ vs ì‹¤ì œ'  # ë ˆì „ë“œì— í‘œì‹œë  ì´ë¦„
        ))

        # ë ˆì´ì•„ì›ƒ ì„¤ì •
        fig_ml_on.update_layout(
            title='âœ…ì „í™˜ìœ¨ ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ',
            xaxis_title='ì‹¤ì œ ì „í™˜ìœ¨',
            yaxis_title='ì˜ˆì¸¡ ì „í™˜ìœ¨',
            height=600,
            xaxis=dict(showgrid=True),  # Xì¶• ê·¸ë¦¬ë“œ í‘œì‹œ
            yaxis=dict(showgrid=True),  # Yì¶• ê·¸ë¦¬ë“œ í‘œì‹œ
        )

        # Streamlitì—ì„œ ì‹œê°í™” í‘œì‹œ
        st.plotly_chart(fig_ml_on)
    
        #âœ…ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ì „í™˜ìœ¨ ì˜ˆì¸¡
        input_data = pd.DataFrame(np.zeros((1, len(features))), columns = features)
        input_data["ì²´ë¥˜ì‹œê°„(min)"] = time_input    #ì„ íƒëœ ì²´ë¥˜ ì‹œê°„ ì…ë ¥

        #ì„ íƒëœ ë””ë°”ì´ìŠ¤ ë° ìœ ì… ê²½ë¡œì— ëŒ€í•œ ì›-í•« ì¸ì½”ë”© ì ìš©
        for device in select_device:
            if f"ë””ë°”ì´ìŠ¤_{device}" in input_data.columns:
                input_data[f"ë””ë°”ì´ìŠ¤_{device}"] = 1

        for path in select_path:
            if f"ìœ ì…ê²½ë¡œ_{path}" in input_data.columns:
                input_data[f"ìœ ì…ê²½ë¡œ_{path}"] = 1

        # ì…ë ¥ ë°ì´í„°ë„ ë™ì¼í•˜ê²Œ í‘œì¤€í™”
        input_data_scaled = scaler.transform(input_data)
        input_data_scaled = pd.DataFrame(input_data_scaled, columns=features)

        #ì „í™˜ìœ¨ ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥
        predicted_conversion = on_model.predict(input_data)[0]

        # ì‹ ë¢°êµ¬ê°„ ê³„ì‚° (ë¶€íŠ¸ìŠ¤íŠ¸ë© ë°©ë²•)
        predictions = []
        for _ in range(100):
            # ë¶€íŠ¸ìŠ¤íŠ¸ë© ìƒ˜í”Œë§
            indices = np.random.choice(len(X_train), size=len(X_train), replace=True)
            X_boot = X_train.iloc[indices]
            y_boot = y_train.iloc[indices]
            
            # ë¶€íŠ¸ìŠ¤íŠ¸ë© ëª¨ë¸ í•™ìŠµ
            boot_model = RandomForestRegressor(n_estimators=50, random_state=np.random.randint(1000))
            boot_model.fit(X_boot, y_boot)
            pred = boot_model.predict(input_data_scaled)[0]
            predictions.append(pred)
        
        confidence_lower = np.percentile(predictions, 2.5)
        confidence_upper = np.percentile(predictions, 97.5)
       
        st.subheader(f"ì˜ˆìƒ ì „í™˜ìœ¨ : {predicted_conversion:.2f}%")
        st.write(f"95% ì‹ ë¢°êµ¬ê°„: {confidence_lower:.2f}% ~ {confidence_upper:.2f}%")

with tab5:  #ë°©ë¬¸ì ìˆ˜ ì˜ˆì¸¡
    # ë°ì´í„° ì¶œë ¥
    with st.expander('ì˜¤í”„ë¼ì¸ ë°ì´í„°'):
        st.dataframe(df_off, use_container_width=True)

    city_options = list(city_mapping.values())

    # í•™ìŠµ ë°ì´í„° ì¤€ë¹„
    df_ml_off = df_off.groupby(["ë‚ ì§œ", "ì§€ì—­"])["ë°©ë¬¸ììˆ˜"].sum().reset_index()
    df_ml_off["ë‚ ì§œ"] = pd.to_datetime(df_ml_off["ë‚ ì§œ"])

    # ì‹œê³„ì—´ í”¼ì²˜
    df_ml_off["year"] = df_ml_off["ë‚ ì§œ"].dt.year
    df_ml_off["month"] = df_ml_off["ë‚ ì§œ"].dt.month
    df_ml_off["day"] = df_ml_off["ë‚ ì§œ"].dt.day
    df_ml_off["day_of_week"] = df_ml_off["ë‚ ì§œ"].dt.weekday
    df_ml_off["quarter"] = df_ml_off["ë‚ ì§œ"].dt.quarter
    df_ml_off["week_of_year"] = df_ml_off["ë‚ ì§œ"].dt.isocalendar().week
    df_ml_off["is_weekend"] = (df_ml_off["day_of_week"] >= 5).astype(int)

    # ê³„ì ˆì„± í”¼ì²˜
    df_ml_off["month_sin"] = np.sin(2 * np.pi * df_ml_off["month"] / 12)
    df_ml_off["month_cos"] = np.cos(2 * np.pi * df_ml_off["month"] / 12)
    df_ml_off["day_sin"] = np.sin(2 * np.pi * df_ml_off["day_of_week"] / 7)
    df_ml_off["day_cos"] = np.cos(2 * np.pi * df_ml_off["day_of_week"] / 7)

    select_region = st.selectbox("ì§€ì—­ì„ ì„ íƒí•˜ì„¸ìš”.", city_options)

    df_region = df_ml_off[df_ml_off["ì§€ì—­"] == select_region]  # íŠ¹ì • ì§€ì—­ ë°ì´í„° ì‚¬ìš©

    # ê²°ì¸¡ê°’ ì²˜ë¦¬
    df_region["ë°©ë¬¸ììˆ˜"] = df_region["ë°©ë¬¸ììˆ˜"].fillna(df_region["ë°©ë¬¸ììˆ˜"].median())

    features = ["year", "month", "day", "day_of_week", "quarter", "week_of_year", 
                "is_weekend", "month_sin", "month_cos", "day_sin", "day_cos"]
    X = df_region[features]
    y = df_region["ë°©ë¬¸ììˆ˜"]

    if st.button("ì˜¤í”„ë¼ì¸ ë°©ë¬¸ì ìˆ˜ ì˜ˆì¸¡"):  # í–¥í›„ 12ê°œì›”ê°„ì˜ ë°©ë¬¸ì ìˆ˜ ì˜ˆì¸¡
        scaler_off = StandardScaler()
        X_scaled = scaler_off.fit_transform(X)
        X_scaled = pd.DataFrame(X_scaled, columns=features)

        # ë°ì´í„° ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

        # ëª¨ë¸ ìƒì„±
        off_model = RandomForestRegressor(
            n_estimators=300,
            max_depth=20,
            min_samples_split=5,
            min_samples_leaf=2,
            max_features='sqrt',
            random_state=42,
            n_jobs=-1,
            oob_score=True
        )

        # ëª¨ë¸ í•™ìŠµ
        off_model.fit(X_train, y_train)

        # ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
        y_pred_test = off_model.predict(X_test)
        mse_off = mean_squared_error(y_test, y_pred_test)
        rmse_off = np.sqrt(mse_off)
        r2_off = r2_score(y_test, y_pred_test)

        # ì„±ëŠ¥ ì§€í‘œ ì¶œë ¥
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("RMSE", f"{rmse_off:.0f}")
        with col2:
            st.metric("RÂ² Score", f"{r2_off:.3f}")
        with col3:
            st.metric("OOB Score", f"{off_model.oob_score_:.3f}")

        # ìµœëŒ€ ë‚ ì§œì˜ ë‹¤ìŒ ë‹¬ë¶€í„° 12ê°œì›” ê°„ì˜ ë‚ ì§œ ìƒì„±
        max_date = df_region["ë‚ ì§œ"].max()
        start_date = (max_date + pd.DateOffset(months=1)).replace(day=1)  # ë‹¤ìŒ ë‹¬ì˜ ì²«ë‚ 
        future_dates = pd.date_range(start=start_date, periods=365, freq="D")
        
        future_df = pd.DataFrame({
            "year": future_dates.year,
            "month": future_dates.month,
            "day": future_dates.day,
            "day_of_week": future_dates.weekday,
            "quarter": future_dates.quarter,
            "week_of_year": future_dates.isocalendar().week,
            "is_weekend": (future_dates.weekday >= 5).astype(int),
            "month_sin": np.sin(2 * np.pi * future_dates.month / 12),
            "month_cos": np.cos(2 * np.pi * future_dates.month / 12),
            "day_sin": np.sin(2 * np.pi * future_dates.weekday / 7),
            "day_cos": np.cos(2 * np.pi * future_dates.weekday / 7)
        })

        # ë¯¸ë˜ ë°ì´í„°ë„ í‘œì¤€í™”
        future_scaled = scaler_off.transform(future_df[features])
        future_scaled = pd.DataFrame(future_scaled, columns=features)
        
        # ë°©ë¬¸ì ìˆ˜ ì˜ˆì¸¡
        future_pred = off_model.predict(future_scaled)
        future_df["ì˜ˆì¸¡ ë°©ë¬¸ì ìˆ˜"] = np.maximum(future_pred, 0)  # ìŒìˆ˜ ë°©ì§€

        # "ë…„-ì›”" í˜•ì‹ì˜ ì¹¼ëŸ¼ ë§Œë“¤ê¸°
        future_df["ë…„ì›”"] = future_df["year"].astype(str) + "-" + future_df["month"].astype(str).str.zfill(2)  # ì›”ì„ ë‘ ìë¦¬ë¡œ í‘œì‹œ

        # ì›” ë³„ë¡œ ì§‘ê³„í•œ ë°©ë¬¸ì ìˆ˜
        future_summary = future_df.groupby("ë…„ì›”", as_index=False)["ì˜ˆì¸¡ ë°©ë¬¸ì ìˆ˜"].sum()

        # ì˜ˆì¸¡ ë°©ë¬¸ì ìˆ˜ í˜•ì‹ ë³€ê²½
        future_summary["ì˜ˆì¸¡ ë°©ë¬¸ì ìˆ˜"] = future_summary["ì˜ˆì¸¡ ë°©ë¬¸ì ìˆ˜"].astype(int).astype(str) + "ëª…"

        st.subheader(f":chart: í–¥í›„ 12ê°œì›” ë™ì•ˆ {select_region}ì˜ ë°©ë¬¸ì ìˆ˜ ì˜ˆì¸¡")

        # ë°©ë¬¸ì ìˆ˜ ì˜ˆì¸¡ ì‹œê°í™”
        fig_ml_off = go.Figure()

        # ì˜ˆì¸¡ ë°©ë¬¸ì ìˆ˜ ì„  ê·¸ë˜í”„ ì¶”ê°€
        fig_ml_off.add_trace(go.Scatter(
            x=future_summary["ë…„ì›”"],
            y=future_summary["ì˜ˆì¸¡ ë°©ë¬¸ì ìˆ˜"].str.extract('(\d+)')[0].astype(int),  # ìˆ«ìë§Œ ì¶”ì¶œí•˜ì—¬ yê°’ìœ¼ë¡œ ì‚¬ìš©
            mode='markers+lines',  # ë§ˆì»¤ì™€ ì„ ì„ ë™ì‹œì— í‘œì‹œ
            marker=dict(symbol='circle', size=8, color='red'),
            line=dict(shape='linear'),
            name='ì˜ˆì¸¡ ë°©ë¬¸ì ìˆ˜'  # ë ˆì „ë“œì— í‘œì‹œë  ì´ë¦„
        ))

        # ë ˆì´ì•„ì›ƒ ì„¤ì •
        fig_ml_off.update_layout(
            title=f"{select_region}ì˜ ë°©ë¬¸ì ìˆ˜ ì˜ˆì¸¡",
            xaxis_title='ë…„-ì›”',
            yaxis_title='ë°©ë¬¸ì ìˆ˜',
            height=600,
            xaxis=dict(showgrid=False),
            yaxis=dict(showgrid=True),
        )

        # Streamlitì—ì„œ ì‹œê°í™”ì™€ ë°ì´í„°í”„ë ˆì„ í‘œì‹œ
        col1, col2 = st.columns(2)

        with col1:
            st.plotly_chart(fig_ml_off)

        with col2:
            st.dataframe(future_summary[["ë…„ì›”", "ì˜ˆì¸¡ ë°©ë¬¸ì ìˆ˜"]], height=550)

        
